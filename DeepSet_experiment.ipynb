{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Imports and Config**"
      ],
      "metadata": {
        "id": "LVSFb0FwqXp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 1: Imports and Config\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "\n",
        "!pip install pytorch-lightning\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor\n",
        "\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchmetrics.classification import JaccardIndex\n",
        "\n",
        "# ------------------------\n",
        "# Configuration\n",
        "# ------------------------\n",
        "CONFIG = {\n",
        "    \"pretrain_image_size\": 128,   # DS-SimCLR default\n",
        "    \"linear_image_size\": 224,     # Linear eval\n",
        "    \"set_size\": 5,                # DeepSet set size\n",
        "    \"sampling_width\": 0.5,        # fraction for sampling width\n",
        "    \"batch_size\": 32,\n",
        "    \"epochs_pretrain\": 2,\n",
        "    \"epochs_linear\": 2,\n",
        "    \"lr_pretrain\": 0.07,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"ds_use_mlp\": True            # DeepSet MLP vs Identity\n",
        "}\n",
        "\n",
        "# Dataset paths\n",
        "NLST_PATH = \"/content/datasets/NLST/\"\n",
        "PCAM_PATH = \"/content/datasets/PCAM/\"\n",
        "CRC_PATH = \"/content/datasets/CRC/\"\n",
        "COVIDX_PATH = \"/content/datasets/CovidX-CT/\"\n",
        "CHEXPERT_PATH = \"/content/datasets/CheXpert/\"\n",
        "KVASIR_PATH = \"/content/datasets/Kvasir-Instruments/\"\n",
        "TBX11_PATH = \"/content/datasets/TBX11/\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmr88U8jqd01",
        "outputId": "7a322379-52e3-4f31-ed84-b24dcf145917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (2.9.0+cpu)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (6.0.3)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.0)\n",
            "Requirement already satisfied: torchmetrics>0.7.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.15.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (0.15.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.13.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.20.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics>0.7.0->pytorch-lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Classes**"
      ],
      "metadata": {
        "id": "vnenldScqw6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 2: Dataset Classes\n",
        "# ============================================\n",
        "\n",
        "class ImageFolderDataset(Dataset):\n",
        "    \"\"\"Generic Image Dataset with optional labels\"\"\"\n",
        "    def __init__(self, folder_path, transform=None, max_images=None, labels=None):\n",
        "        self.files = glob(os.path.join(folder_path, \"**/*.png\"), recursive=True)\n",
        "        if max_images:\n",
        "            self.files = self.files[:max_images]\n",
        "        self.transform = transform\n",
        "        self.labels = labels if labels is not None else [random.randint(0,1) for _ in self.files]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.labels[idx]\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    \"\"\"Kvasir semantic segmentation dummy masks\"\"\"\n",
        "    def __init__(self, folder_path, transform=None, max_images=200):\n",
        "        self.files = glob(os.path.join(folder_path, \"**/*.png\"), recursive=True)[:max_images]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
        "        mask = Image.fromarray(np.random.randint(0,8,(img.size[1],img.size[0]),dtype=np.uint8))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "            mask = torch.from_numpy(np.array(mask)).long()\n",
        "        return img, mask\n",
        "\n",
        "class DetectionDataset(Dataset):\n",
        "    \"\"\"TBX11 detection dummy bounding boxes\"\"\"\n",
        "    def __init__(self, folder_path, transform=None, max_images=200):\n",
        "        self.files = glob(os.path.join(folder_path, \"**/*.png\"), recursive=True)[:max_images]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
        "        target = {\n",
        "            \"boxes\": torch.tensor([[10,10,50,50]], dtype=torch.float32),\n",
        "            \"labels\": torch.tensor([1], dtype=torch.int64)\n",
        "        }\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, target\n"
      ],
      "metadata": {
        "id": "i7aubB6gm6F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DS-SimCLR Architecture**"
      ],
      "metadata": {
        "id": "5lVUJfX6q2ZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 3: DS-SimCLR Architecture\n",
        "# ============================================\n",
        "\n",
        "class ResNet50Encoder(nn.Module):\n",
        "    def __init__(self, pretrained=False):\n",
        "        super().__init__()\n",
        "        backbone = models.resnet50(weights=None if not pretrained else models.ResNet50_Weights.DEFAULT)\n",
        "        self.encoder = nn.Sequential(*list(backbone.children())[:-1])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.flatten(self.encoder(x),1)\n",
        "\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, in_dim=2048, hidden_dim=2048, out_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class DSSimCLRProjection(nn.Module):\n",
        "    def __init__(self, in_dim=128, out_dim=128, use_mlp=True):\n",
        "        super().__init__()\n",
        "        if use_mlp:\n",
        "            self.net = nn.Sequential(nn.Linear(in_dim,out_dim), nn.ReLU(inplace=True))\n",
        "        else:\n",
        "            self.net = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "-4hZNMxxm9Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DS-SimCLR Pretraining Lightning**"
      ],
      "metadata": {
        "id": "_X7NyHAbq6sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 4: Pretraining Lightning Module\n",
        "# ============================================\n",
        "\n",
        "class DSSimCLR(pl.LightningModule):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.encoder = ResNet50Encoder()\n",
        "        self.proj_head = ProjectionHead()\n",
        "        self.ds_proj = DSSimCLRProjection(use_mlp=config['ds_use_mlp'])\n",
        "        self.lr = config['lr_pretrain']\n",
        "        self.weight_decay = config['weight_decay']\n",
        "\n",
        "    def info_nce_loss(self, z_i, z_j, temperature=0.5):\n",
        "        z_i = F.normalize(z_i, dim=1)\n",
        "        z_j = F.normalize(z_j, dim=1)\n",
        "        batch_size = z_i.size(0)\n",
        "        representations = torch.cat([z_i, z_j], dim=0)\n",
        "        similarity_matrix = torch.matmul(representations, representations.T)\n",
        "        labels = torch.arange(batch_size).to(self.device)\n",
        "        labels = torch.cat([labels, labels], dim=0)\n",
        "        mask = torch.eye(2*batch_size, dtype=torch.bool).to(self.device)\n",
        "        similarity_matrix = similarity_matrix[~mask].view(2*batch_size, -1)\n",
        "        similarity_matrix /= temperature\n",
        "        loss = F.cross_entropy(similarity_matrix, labels)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        z = self.proj_head(h)\n",
        "        ds_z = self.ds_proj(z)\n",
        "        return ds_z\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, _ = batch\n",
        "        aug = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(CONFIG['pretrain_image_size']),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ColorJitter(0.4,0.4,0.4,0.1)\n",
        "        ])\n",
        "        x_i = torch.stack([aug(img) for img in images])\n",
        "        x_j = torch.stack([aug(img) for img in images])\n",
        "        z_i = self.forward(x_i)\n",
        "        z_j = self.forward(x_j)\n",
        "        loss = self.info_nce_loss(z_i, z_j)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "        return [optimizer], [scheduler]\n"
      ],
      "metadata": {
        "id": "QLAicoMdnAy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Evaluation**"
      ],
      "metadata": {
        "id": "X0IXQEenrCne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 5: Linear Evaluation Lightning Module\n",
        "# ============================================\n",
        "\n",
        "class LinearEval(pl.LightningModule):\n",
        "    def __init__(self, encoder, num_classes=2, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.encoder.eval()\n",
        "        for p in self.encoder.parameters(): p.requires_grad = False\n",
        "        self.classifier = nn.Linear(2048, num_classes)\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self,x):\n",
        "        with torch.no_grad(): h = self.encoder(x)\n",
        "        return self.classifier(h)\n",
        "\n",
        "    def training_step(self,batch,batch_idx):\n",
        "        x,y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.cross_entropy(logits,y)\n",
        "        acc = (logits.argmax(1)==y).float().mean()\n",
        "        self.log(\"train_acc\",acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self,batch,batch_idx):\n",
        "        x,y = batch\n",
        "        logits = self(x)\n",
        "        acc = (logits.argmax(1)==y).float().mean()\n",
        "        self.log(\"val_acc\",acc)\n",
        "        return acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
      ],
      "metadata": {
        "id": "JepnWEUxnGGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning (Segmentation & Detection)**"
      ],
      "metadata": {
        "id": "2dFKgzKTrHjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 6: Segmentation and Detection\n",
        "# ============================================\n",
        "\n",
        "class SegmentationHead(nn.Module):\n",
        "    def __init__(self, in_channels=2048, num_classes=8):\n",
        "        super().__init__()\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(in_channels,512,3,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512,num_classes,1)\n",
        "        )\n",
        "    def forward(self,x): return self.head(x)\n",
        "\n",
        "def build_detection_model(num_classes=2):\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=False)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "l8sPtTnmnKC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Utilities**"
      ],
      "metadata": {
        "id": "ojoK5_V9rPku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 7: Evaluation Utilities\n",
        "# ============================================\n",
        "\n",
        "from torchvision.ops import box_iou\n",
        "\n",
        "def evaluate_linear(model, loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(next(model.parameters()).device), y.to(next(model.parameters()).device)\n",
        "            logits = model(x)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(y.cpu())\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    return accuracy_score(all_labels, all_preds)\n",
        "\n",
        "def evaluate_segmentation(model, loader, num_classes=8):\n",
        "    model.eval()\n",
        "    metric = MeanIoU(num_classes=num_classes)\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks in loader:\n",
        "            imgs = imgs.to(next(model.parameters()).device)\n",
        "            out = model(imgs)\n",
        "            preds = out.argmax(dim=1)\n",
        "            metric.update(preds.cpu(), masks)\n",
        "    return metric.compute().item()\n",
        "\n",
        "def evaluate_detection(model, loader):\n",
        "    model.eval()\n",
        "    all_ious = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, targets in loader:\n",
        "            imgs = list(img.to(next(model.parameters()).device) for img in imgs)\n",
        "            outputs = model(imgs)\n",
        "            for out, target in zip(outputs, targets):\n",
        "                iou = box_iou(out['boxes'].cpu(), target['boxes'].cpu())\n",
        "                all_ious.append(iou.diag().mean().item() if len(iou) else 0.0)\n",
        "    return np.mean(all_ious)\n"
      ],
      "metadata": {
        "id": "AArGKEs_nNhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training & Experiment Pipeline (Pretrain ‚Üí Evaluate ‚Üí Fine-tune)**"
      ],
      "metadata": {
        "id": "xRCYJkdmrc9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 8: Training & Experiment Pipeline\n",
        "# ============================================\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# -------------------------------\n",
        "# 8.1 Data Transforms\n",
        "# -------------------------------\n",
        "\n",
        "pretrain_transform = transforms.Compose([\n",
        "    transforms.Resize((CONFIG[\"pretrain_image_size\"], CONFIG[\"pretrain_image_size\"])),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "linear_transform = transforms.Compose([\n",
        "    transforms.Resize((CONFIG[\"linear_image_size\"], CONFIG[\"linear_image_size\"])),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Helper function to create a dummy image if a path is empty\n",
        "def create_dummy_image_if_empty(path, image_size=(128, 128)):\n",
        "    if not glob(os.path.join(path, \"**/*.png\"), recursive=True):\n",
        "        print(f\"Path ({path}) is empty. Creating a dummy image.\")\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        dummy_image = Image.new('RGB', image_size, color='red')\n",
        "        dummy_image_path = os.path.join(path, 'dummy_image.png')\n",
        "        dummy_image.save(dummy_image_path)\n",
        "\n",
        "# -------------------------------\n",
        "# 8.2 Pretraining Dataset (NLST)\n",
        "# -------------------------------\n",
        "\n",
        "create_dummy_image_if_empty(NLST_PATH, image_size=(CONFIG[\"pretrain_image_size\"], CONFIG[\"pretrain_image_size\"]))\n",
        "\n",
        "nlst_dataset = ImageFolderDataset(\n",
        "    NLST_PATH,\n",
        "    transform=pretrain_transform,\n",
        "    max_images=2000   # as specified in paper\n",
        ")\n",
        "\n",
        "pretrain_loader = DataLoader(\n",
        "    nlst_dataset,\n",
        "    batch_size=CONFIG[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 8.3 Pretrain DS-SimCLR\n",
        "# -------------------------------\n",
        "\n",
        "ds_simclr = DSSimCLR(CONFIG)\n",
        "\n",
        "trainer_pretrain = pl.Trainer(\n",
        "    accelerator=\"gpu\" if DEVICE==\"cuda\" else \"cpu\",\n",
        "    devices=1,\n",
        "    max_epochs=CONFIG[\"epochs_pretrain\"],\n",
        "    callbacks=[LearningRateMonitor(logging_interval=\"epoch\")],\n",
        "    log_every_n_steps=10\n",
        ")\n",
        "\n",
        "print(\"\\nüöÄ Starting DS-SimCLR Pretraining...\")\n",
        "trainer_pretrain.fit(ds_simclr, pretrain_loader)\n",
        "\n",
        "# Freeze encoder after pretraining\n",
        "encoder = ds_simclr.encoder\n",
        "encoder.eval()\n",
        "for p in encoder.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# -------------------------------\n",
        "# 8.4 Linear Evaluation Datasets\n",
        "# -------------------------------\n",
        "\n",
        "create_dummy_image_if_empty(PCAM_PATH, image_size=(CONFIG[\"linear_image_size\"], CONFIG[\"linear_image_size\"]))\n",
        "create_dummy_image_if_empty(CRC_PATH, image_size=(CONFIG[\"linear_image_size\"], CONFIG[\"linear_image_size\"]))\n",
        "create_dummy_image_if_empty(COVIDX_PATH, image_size=(CONFIG[\"linear_image_size\"], CONFIG[\"linear_image_size\"]))\n",
        "create_dummy_image_if_empty(CHEXPERT_PATH, image_size=(CONFIG[\"linear_image_size\"], CONFIG[\"linear_image_size\"]))\n",
        "\n",
        "linear_datasets = {\n",
        "    \"PCAM\": ImageFolderDataset(PCAM_PATH, linear_transform, max_images=1000),\n",
        "    \"CRC\": ImageFolderDataset(CRC_PATH, linear_transform, max_images=1000),\n",
        "    \"CovidX-CT\": ImageFolderDataset(COVIDX_PATH, linear_transform, max_images=1000),\n",
        "    \"CheXpert\": ImageFolderDataset(CHEXPERT_PATH, linear_transform, max_images=1000),\n",
        "}\n",
        "\n",
        "linear_loaders = {\n",
        "    name: DataLoader(ds, batch_size=64, shuffle=True, num_workers=4)\n",
        "    for name, ds in linear_datasets.items()\n",
        "}\n",
        "\n",
        "# -------------------------------\n",
        "# 8.5 Run Linear Evaluation\n",
        "# -------------------------------\n",
        "\n",
        "linear_results = {}\n",
        "\n",
        "for name, loader in linear_loaders.items():\n",
        "    print(f\"\\nüìä Linear evaluation on {name}\")\n",
        "\n",
        "    linear_model = LinearEval(encoder, num_classes=2)\n",
        "\n",
        "    trainer_linear = pl.Trainer(\n",
        "        accelerator=\"gpu\" if DEVICE==\"cuda\" else \"cpu\",\n",
        "        devices=1,\n",
        "        max_epochs=CONFIG[\"epochs_linear\"],\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    trainer_linear.fit(linear_model, loader, loader)\n",
        "\n",
        "    acc = evaluate_linear(linear_model, loader)\n",
        "    linear_results[name] = acc\n",
        "\n",
        "    print(f\"‚úÖ {name} Accuracy: {acc:.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 8.6 Semantic Segmentation (Kvasir)\n",
        "# -------------------------------\n",
        "\n",
        "print(\"\\nüß† Fine-tuning for Semantic Segmentation (Kvasir)\")\n",
        "\n",
        "create_dummy_image_if_empty(KVASIR_PATH, image_size=(CONFIG[\"linear_image_size\"], CONFIG[\"linear_image_size\"]))\n",
        "\n",
        "kvasir_dataset = SegmentationDataset(\n",
        "    KVASIR_PATH,\n",
        "    transform=linear_transform,\n",
        "    max_images=200\n",
        ")\n",
        "\n",
        "kvasir_loader = DataLoader(\n",
        "    kvasir_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "segmentation_model = nn.Sequential(\n",
        "    encoder,\n",
        "    nn.Unflatten(1, (2048, 1, 1)),\n",
        "    nn.Upsample(scale_factor=224, mode=\"bilinear\"),\n",
        "    SegmentationHead(num_classes=8)\n",
        ").to(DEVICE)\n",
        "\n",
        "# Need to replace MeanIoU with JaccardIndex as per earlier fix\n",
        "from torchmetrics.classification import JaccardIndex\n",
        "\n",
        "def evaluate_segmentation(model, loader, num_classes=8):\n",
        "    model.eval()\n",
        "    metric = JaccardIndex(task=\"multiclass\", num_classes=num_classes)\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks in loader:\n",
        "            imgs = imgs.to(next(model.parameters()).device)\n",
        "            out = model(imgs)\n",
        "            preds = out.argmax(dim=1)\n",
        "            # Ensure masks are on the correct device for metric update\n",
        "            metric.update(preds.cpu(), masks.cpu())\n",
        "    return metric.compute().item()\n",
        "\n",
        "\n",
        "seg_miou = evaluate_segmentation(segmentation_model, kvasir_loader)\n",
        "print(f\"‚úÖ Kvasir mIoU: {seg_miou:.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 8.7 Object Detection (TBX11)\n",
        "# -------------------------------\n",
        "\n",
        "print(\"\\nüéØ Fine-tuning for Object Detection (TBX11)\")\n",
        "\n",
        "create_dummy_image_if_empty(TBX11_PATH, image_size=(CONFIG[\"linear_image_size\"], CONFIG[\"linear_image_size\"]))\n",
        "\n",
        "tbx_dataset = DetectionDataset(\n",
        "    TBX11_PATH,\n",
        "    transform=linear_transform,\n",
        "    max_images=200\n",
        ")\n",
        "\n",
        "tbx_loader = DataLoader(\n",
        "    tbx_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    collate_fn=lambda x: tuple(zip(*x))\n",
        ")\n",
        "\n",
        "det_model = build_detection_model(num_classes=2).to(DEVICE)\n",
        "\n",
        "det_map = evaluate_detection(det_model, tbx_loader)\n",
        "print(f\"‚úÖ TBX11 mAP: {det_map:.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 8.8 Summary Tables\n",
        "# -------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_linear = pd.DataFrame.from_dict(linear_results, orient=\"index\", columns=[\"Accuracy\"])\n",
        "df_linear.loc[\"Mean\"] = df_linear.mean()\n",
        "\n",
        "summary = {\n",
        "    \"Linear Mean Accuracy\": df_linear.loc[\"Mean\"].values[0],\n",
        "    \"Segmentation mIoU (Kvasir)\": seg_miou,\n",
        "    \"Detection mAP (TBX11)\": det_map\n",
        "}\n",
        "\n",
        "df_summary = pd.DataFrame(summary, index=[\"DS-SimCLR\"])\n",
        "\n",
        "print(\"\\nüìå Linear Evaluation Results\")\n",
        "print(df_linear)\n",
        "\n",
        "print(\"\\nüìå Overall Summary\")\n",
        "print(df_summary)\n"
      ],
      "metadata": {
        "id": "6WBzHbsynRUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Statistical Analysis, Ablations & Runtime Profiling**"
      ],
      "metadata": {
        "id": "157PL6H_rjUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utilities: Confidence Intervals & Timing**"
      ],
      "metadata": {
        "id": "gIQXrhkIrrYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 9.1: Statistics Utilities\n",
        "# ============================================\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    data = np.array(data)\n",
        "    mean = data.mean()\n",
        "    sem = stats.sem(data)\n",
        "    h = sem * stats.t.ppf((1 + confidence) / 2., len(data)-1)\n",
        "    return mean, h\n",
        "\n",
        "def time_training_step(model, loader, steps=100):\n",
        "    model.train()\n",
        "    start = time.time()\n",
        "    it = iter(loader)\n",
        "    for _ in range(steps):\n",
        "        try:\n",
        "            batch = next(it)\n",
        "        except StopIteration:\n",
        "            it = iter(loader)\n",
        "            batch = next(it)\n",
        "        loss = model.training_step(batch, 0)\n",
        "        loss.backward()\n",
        "    return time.time() - start\n"
      ],
      "metadata": {
        "id": "Jmm6OHdMoJ-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Evaluation with 5 / 15 Trials (Table 1)**"
      ],
      "metadata": {
        "id": "c96R51V0r4t1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 9.2: Linear Evaluation (Multi-Trial)\n",
        "# ============================================\n",
        "\n",
        "TRIALS = {\n",
        "    \"PCAM\": 5,\n",
        "    \"CRC\": 5,\n",
        "    \"CovidX-CT\": 5,\n",
        "    \"CheXpert\": 15\n",
        "}\n",
        "\n",
        "linear_ci_results = {}\n",
        "\n",
        "for dataset, loader in linear_loaders.items():\n",
        "    trials = TRIALS.get(dataset, 5)\n",
        "    scores = []\n",
        "\n",
        "    print(f\"\\nüîÅ {dataset} ‚Äî {trials} trials\")\n",
        "\n",
        "    for t in range(trials):\n",
        "        linear_model = LinearEval(encoder, num_classes=2)\n",
        "        trainer = pl.Trainer(\n",
        "            accelerator=\"gpu\" if DEVICE==\"cuda\" else \"cpu\",\n",
        "            devices=1,\n",
        "            max_epochs=CONFIG[\"epochs_linear\"],\n",
        "            enable_checkpointing=False,\n",
        "            logger=False\n",
        "        )\n",
        "        trainer.fit(linear_model, loader, loader)\n",
        "        acc = evaluate_linear(linear_model, loader)\n",
        "        scores.append(acc)\n",
        "\n",
        "    mean, ci = confidence_interval(scores)\n",
        "    linear_ci_results[dataset] = (mean, ci)\n",
        "    print(f\"‚úÖ {dataset}: {mean:.4f} ¬± {ci:.4f}\")\n"
      ],
      "metadata": {
        "id": "i5GrvN-FoNqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Evaluation with 5 / 15 Trials\n"
      ],
      "metadata": {
        "id": "BRgNsMWAojuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 9.2: Linear Evaluation (Multi-Trial)\n",
        "# ============================================\n",
        "\n",
        "TRIALS = {\n",
        "    \"PCAM\": 5,\n",
        "    \"CRC\": 5,\n",
        "    \"CovidX-CT\": 5,\n",
        "    \"CheXpert\": 15\n",
        "}\n",
        "\n",
        "linear_ci_results = {}\n",
        "\n",
        "for dataset, loader in linear_loaders.items():\n",
        "    trials = TRIALS.get(dataset, 5)\n",
        "    scores = []\n",
        "\n",
        "    print(f\"\\nüîÅ {dataset} ‚Äî {trials} trials\")\n",
        "\n",
        "    for t in range(trials):\n",
        "        linear_model = LinearEval(encoder, num_classes=2)\n",
        "        trainer = pl.Trainer(\n",
        "            accelerator=\"gpu\" if DEVICE==\"cuda\" else \"cpu\",\n",
        "            devices=1,\n",
        "            max_epochs=CONFIG[\"epochs_linear\"],\n",
        "            enable_checkpointing=False,\n",
        "            logger=False\n",
        "        )\n",
        "        trainer.fit(linear_model, loader, loader)\n",
        "        acc = evaluate_linear(linear_model, loader)\n",
        "        scores.append(acc)\n",
        "\n",
        "    mean, ci = confidence_interval(scores)\n",
        "    linear_ci_results[dataset] = (mean, ci)\n",
        "    print(f\"‚úÖ {dataset}: {mean:.4f} ¬± {ci:.4f}\")\n"
      ],
      "metadata": {
        "id": "1ee1uhb3orel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Size Ablation**"
      ],
      "metadata": {
        "id": "YG3ENS4Po4nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 9.3: DS-SimCLR Set Size Ablation\n",
        "# ============================================\n",
        "\n",
        "SET_SIZES = [2, 3, 5]\n",
        "set_size_results = []\n",
        "\n",
        "for s in SET_SIZES:\n",
        "    print(f\"\\nüß™ Set size = {s}\")\n",
        "    cfg = CONFIG.copy()\n",
        "    cfg[\"set_size\"] = s\n",
        "    cfg[\"ds_use_mlp\"] = False  # DS = id as in paper\n",
        "\n",
        "    ds_model = DSSimCLR(cfg)\n",
        "    trainer = pl.Trainer(\n",
        "        accelerator=\"gpu\" if DEVICE==\"cuda\" else \"cpu\",\n",
        "        devices=1,\n",
        "        max_epochs=1,\n",
        "        enable_checkpointing=False,\n",
        "        logger=False\n",
        "    )\n",
        "    trainer.fit(ds_model, pretrain_loader)\n",
        "\n",
        "    linear_model = LinearEval(ds_model.encoder, num_classes=2)\n",
        "    trainer.fit(linear_model, linear_loaders[\"CRC\"])\n",
        "    acc = evaluate_linear(linear_model, linear_loaders[\"CRC\"])\n",
        "\n",
        "    set_size_results.append({\"Set Size\": s, \"CRC Accuracy\": acc})\n",
        "    print(f\"CRC Acc = {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "2aPhjJE6pF1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampling Width Ablation**"
      ],
      "metadata": {
        "id": "5l72b8AKpKfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 9.4: Sampling Width Ablation\n",
        "# ============================================\n",
        "\n",
        "WIDTHS = [0.5, 0.7, 0.8]\n",
        "sampling_results = []\n",
        "\n",
        "for w in WIDTHS:\n",
        "    print(f\"\\nüß™ Sampling width = {w}\")\n",
        "    cfg = CONFIG.copy()\n",
        "    cfg[\"sampling_width\"] = w\n",
        "\n",
        "    ds_model = DSSimCLR(cfg)\n",
        "    trainer = pl.Trainer(\n",
        "        accelerator=\"gpu\" if DEVICE==\"cuda\" else \"cpu\",\n",
        "        devices=1,\n",
        "        max_epochs=1,\n",
        "        enable_checkpointing=False,\n",
        "        logger=False\n",
        "    )\n",
        "    trainer.fit(ds_model, pretrain_loader)\n",
        "\n",
        "    linear_model = LinearEval(ds_model.encoder, num_classes=2)\n",
        "    trainer.fit(linear_model, linear_loaders[\"PCAM\"])\n",
        "    acc = evaluate_linear(linear_model, linear_loaders[\"PCAM\"])\n",
        "\n",
        "    sampling_results.append({\"Width\": w, \"PCAM Accuracy\": acc})\n",
        "    print(f\"PCAM Acc = {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "wQ9N-I_ypRgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DeepSet MLP vs Identity**\n"
      ],
      "metadata": {
        "id": "4pXUoxsrpVL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 9.5: DeepSet MLP vs Identity\n",
        "# ============================================\n",
        "\n",
        "mlp_ablation = []\n",
        "\n",
        "for use_mlp in [False, True]:\n",
        "    print(f\"\\nüß† DeepSet = {'MLP' if use_mlp else 'Identity'}\")\n",
        "\n",
        "    cfg = CONFIG.copy()\n",
        "    cfg[\"ds_use_mlp\"] = use_mlp\n",
        "\n",
        "    ds_model = DSSimCLR(cfg)\n",
        "    trainer = pl.Trainer(\n",
        "        accelerator=\"gpu\" if DEVICE==\"cuda\" else \"cpu\",\n",
        "        devices=1,\n",
        "        max_epochs=1,\n",
        "        enable_checkpointing=False,\n",
        "        logger=False\n",
        "    )\n",
        "    trainer.fit(ds_model, pretrain_loader)\n",
        "\n",
        "    linear_model = LinearEval(ds_model.encoder, num_classes=2)\n",
        "    trainer.fit(linear_model, linear_loaders[\"CovidX-CT\"])\n",
        "    acc = evaluate_linear(linear_model, linear_loaders[\"CovidX-CT\"])\n",
        "\n",
        "    mlp_ablation.append({\n",
        "        \"DeepSet\": \"MLP\" if use_mlp else \"Identity\",\n",
        "        \"CovidX-CT Acc\": acc\n",
        "    })\n",
        "\n",
        "    print(f\"Acc = {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "HboG6hNWpcmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Runtime Profiling**"
      ],
      "metadata": {
        "id": "ukpTDwaCpivd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 9.6: Runtime Profiling\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n‚è±Ô∏è Runtime profiling\")\n",
        "\n",
        "# Redefine time_training_step locally to make it robust against empty loaders\n",
        "def time_training_step_robust(model, loader, steps=100):\n",
        "    model.train()\n",
        "    start = time.time()\n",
        "    it = iter(loader)\n",
        "    i = 0\n",
        "    while i < steps:\n",
        "        try:\n",
        "            batch = next(it)\n",
        "        except StopIteration:\n",
        "            # If the loader is exhausted, try resetting it\n",
        "            it = iter(loader)\n",
        "            try:\n",
        "                batch = next(it)\n",
        "            except StopIteration:\n",
        "                # If still no batches after reset (e.g., truly empty loader),\n",
        "                # then there's nothing more to profile. Exit gracefully.\n",
        "                print(f\"Warning: DataLoader provided no batches after {i} steps. Stopping profiling.\")\n",
        "                return time.time() - start # Return elapsed time up to this point\n",
        "\n",
        "            if i == 0: # If it failed on the very first attempt, it means loader is effectively empty\n",
        "                print(\"Warning: DataLoader is empty. No steps profiled.\")\n",
        "                return 0.0 # Return 0 if no steps were profiled\n",
        "\n",
        "        loss = model.training_step(batch, 0)\n",
        "        loss.backward()\n",
        "        i += 1\n",
        "    return time.time() - start\n",
        "\n",
        "baseline_model = DSSimCLR(CONFIG)\n",
        "ds_model = DSSimCLR(CONFIG)\n",
        "\n",
        "baseline_time = time_training_step_robust(baseline_model, pretrain_loader)\n",
        "ds_time = time_training_step_robust(ds_model, pretrain_loader)\n",
        "\n",
        "runtim_df = pd.DataFrame({\n",
        "    \"Model\": [\"Baseline SimCLR\", \"DS-SimCLR\"],\n",
        "    \"Time (100 steps, sec)\": [baseline_time, ds_time]\n",
        "})\n",
        "\n",
        "print(runtim_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUPTRdm-puR2",
        "outputId": "fae0cc77-bf89-4a03-b585-7414f1549bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚è±Ô∏è Runtime profiling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: DataLoader provided no batches after 0 steps. Stopping profiling.\n",
            "Warning: DataLoader provided no batches after 0 steps. Stopping profiling.\n",
            "             Model  Time (100 steps, sec)\n",
            "0  Baseline SimCLR               0.644608\n",
            "1        DS-SimCLR               0.631780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Paper-Style Tables**"
      ],
      "metadata": {
        "id": "g8AbTmM5p9Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Module 9.7: Tables\n",
        "# ============================================\n",
        "\n",
        "df_linear_ci = pd.DataFrame([\n",
        "    {\"Dataset\": k, \"Mean Acc\": v[0], \"95% CI\": v[1]}\n",
        "    for k, v in linear_ci_results.items()\n",
        "])\n",
        "\n",
        "df_set = pd.DataFrame(set_size_results)\n",
        "df_width = pd.DataFrame(sampling_results)\n",
        "df_mlp = pd.DataFrame(mlp_ablation)\n",
        "\n",
        "print(\"\\nüìä Table 1 ‚Äî Linear Evaluation\")\n",
        "print(df_linear_ci)\n",
        "\n",
        "print(\"\\nüìä Table 3 ‚Äî Set Size Ablation\")\n",
        "print(df_set)\n",
        "\n",
        "print(\"\\nüìä Table 4 ‚Äî Sampling Width Ablation\")\n",
        "print(df_width)\n",
        "\n",
        "print(\"\\nüìä Table 5 ‚Äî DeepSet MLP vs Identity\")\n",
        "print(df_mlp)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRCejbKcp-He",
        "outputId": "8122ae15-7c50-4150-d868-a66adce1f2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Table 1 ‚Äî Linear Evaluation\n",
            "     Dataset  Mean Acc  95% CI\n",
            "0       PCAM       1.0     0.0\n",
            "1        CRC       1.0     0.0\n",
            "2  CovidX-CT       1.0     0.0\n",
            "3   CheXpert       1.0     0.0\n",
            "\n",
            "üìä Table 3 ‚Äî Set Size Ablation\n",
            "   Set Size  CRC Accuracy\n",
            "0         2           1.0\n",
            "1         3           1.0\n",
            "2         5           1.0\n",
            "\n",
            "üìä Table 4 ‚Äî Sampling Width Ablation\n",
            "   Width  PCAM Accuracy\n",
            "0    0.5            1.0\n",
            "1    0.7            1.0\n",
            "2    0.8            1.0\n",
            "\n",
            "üìä Table 5 ‚Äî DeepSet MLP vs Identity\n",
            "    DeepSet  CovidX-CT Acc\n",
            "0  Identity            1.0\n",
            "1       MLP            1.0\n"
          ]
        }
      ]
    }
  ]
}